{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cee7e3",
   "metadata": {},
   "source": [
    "# Using Gemini in AutoGen with Other LLMs\n",
    "\n",
    "You don't need to handle OpenAI or Google's GenAI packages. AutoGen already handled all of these for you.\n",
    "\n",
    "You can just create different agents with different backend LLM with assistant agent, and all models/agents are at your fingertip.\n",
    "\n",
    "\n",
    "## Main Distinctions\n",
    "- Gemini does not have the \"system_message\" field (correct me if I am wrong). So, it's instruction following skills are not as strong as GPTs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0beb1-4e51-4af0-897f-f5080e2a0fb4",
   "metadata": {},
   "source": [
    "### Recommendations for use of api keys: https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801d13b",
   "metadata": {},
   "source": [
    "Sample OAI_CONFIG_LIST \n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-35-turbo\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"base_url\": \"https://tnrllmproxy.azurewebsites.net/v1\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"dalle\",\n",
    "        \"api_key\": \"your OpenAI Key goes here\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"api_key\": \"your Google's GenAI Key goes here\",\n",
    "        \"api_type\": \"google\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gemini-pro-vision\",\n",
    "        \"api_key\": \"your Google's GenAI Key goes here\",\n",
    "        \"api_type\": \"google\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fee066",
   "metadata": {},
   "source": [
    "### Before everything starts, install AutoGen with the `gemini` option\n",
    "```bash\n",
    "pip install \"pyautogen[gemini]~=0.2.0b4\"\n",
    "```\n",
    "\n",
    "\n",
    "#### Install These Missing Packages Manually if You Encounter Any Errors\n",
    "```bash\n",
    "pip install https://github.com/microsoft/autogen/archive/gemini.zip\n",
    "pip install \"google-generativeai\" \"pydash\" \"pillow\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f221c7-1e69-46a6-ba44-f5736b90e9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --user \"pyautogen[gemini]~=0.2.0b4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da1913-a7bd-462c-bdfd-8701f6cb02ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install --user \"google-generativeai\" \"pydash\" \"pillow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37cd165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pdb\n",
    "import os\n",
    "import re\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, Agent, UserProxyAgent, ConversableAgent\n",
    "\n",
    "from autogen.agentchat.contrib.img_utils import get_image_data, _to_pil\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "from termcolor import colored\n",
    "import random\n",
    "\n",
    "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb2d08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ed6b642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config_list_gemini = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f09481",
   "metadata": {},
   "source": [
    "## Gemini Assitant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a71ba6-ca24-4778-84cd-47920bcf5053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Sort the array with Bubble Sort: [4, 1, 3, 2]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "```python\n",
      "def bubble_sort(arr):\n",
      "    \"\"\"\n",
      "    Bubble Sort Function\n",
      "    arr: list of integers to be sorted\n",
      "    \"\"\"\n",
      "    n = len(arr)\n",
      "    for i in range(n-1):\n",
      "        for j in range(0, n-i-1):\n",
      "            if arr[j] > arr[j+1]:\n",
      "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "    return arr\n",
      "\n",
      "# Sort the array with Bubble Sort: [4, 1, 3, 2]\n",
      "arr = [4, 1, 3, 2]\n",
      "print(bubble_sort(arr))  # [1, 2, 3, 4]\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "[1, 2, 3, 4]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Sort the array with Bubble Sort: [4, 1, 3, 2]', 'role': 'assistant'}, {'content': '```python\\ndef bubble_sort(arr):\\n    \"\"\"\\n    Bubble Sort Function\\n    arr: list of integers to be sorted\\n    \"\"\"\\n    n = len(arr)\\n    for i in range(n-1):\\n        for j in range(0, n-i-1):\\n            if arr[j] > arr[j+1]:\\n                arr[j], arr[j+1] = arr[j+1], arr[j]\\n    return arr\\n\\n# Sort the array with Bubble Sort: [4, 1, 3, 2]\\narr = [4, 1, 3, 2]\\nprint(bubble_sort(arr))  # [1, 2, 3, 4]\\n```', 'role': 'user'}, {'content': 'exitcode: 0 (execution succeeded)\\nCode output: \\n[1, 2, 3, 4]\\n', 'role': 'assistant'}, {'content': 'TERMINATE', 'role': 'user'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.0008435000000000001, 'gemini-pro': {'cost': 0.0008435000000000001, 'prompt_tokens': 1180, 'completion_tokens': 169, 'total_tokens': 1349}}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant = AssistantAgent(\"assistant\", \n",
    "                           llm_config={\"config_list\": config_list_gemini, \"seed\": 42}, \n",
    "                           max_consecutive_auto_reply=3)\n",
    "# print(assistant.system_message)\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                            code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False}, \n",
    "                            human_input_mode=\"NEVER\", \n",
    "                           is_termination_msg = lambda x: content_str(x.get(\"content\")).find(\"TERMINATE\") >= 0)\n",
    "\n",
    "user_proxy.initiate_chat(assistant, message=\"Sort the array with Bubble Sort: [4, 1, 3, 2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ac576-0df6-44f1-8c06-00c68e96f24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d2f22-c6a2-4da2-8d5d-1e9d3a3fcf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de85984",
   "metadata": {},
   "source": [
    "## Agent Collaboration and Interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beb32c92-069c-424c-9bac-e2e15378354c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_config1={\"config_list\": config_list_gpt4, \"seed\": 42}\n",
    "llm_config2={\"config_list\": config_list_gemini, \"seed\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c395c4-0feb-4e95-93b1-358041ff9779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(config_list_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8af7529f-440d-4ff3-8691-6b1cbb5addfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mgpt-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "What are computers?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "Computers are electronic devices used to process and store data. They are commonly used for word processing, programming, web browsing, gaming, and more.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mgpt-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "What is the difference between a computer and a calculator?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "Computers are versatile machines capable of performing a wide range of tasks, from basic calculations to complex simulations. Calculators, on the other hand, are specialized devices designed primarily for performing mathematical operations.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mgpt-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "What is the difference between hardware and software?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "Hardware refers to the physical components of a computer system, such as the processor, memory, and storage devices. Software, on the other hand, consists of the instructions and programs that tell the hardware how to operate and perform specific tasks.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What are computers?', 'role': 'assistant'}, {'content': 'Computers are electronic devices used to process and store data. They are commonly used for word processing, programming, web browsing, gaming, and more.', 'role': 'user'}, {'content': 'What is the difference between a computer and a calculator?', 'role': 'assistant'}, {'content': 'Computers are versatile machines capable of performing a wide range of tasks, from basic calculations to complex simulations. Calculators, on the other hand, are specialized devices designed primarily for performing mathematical operations.', 'role': 'user'}, {'content': 'What is the difference between hardware and software?', 'role': 'assistant'}, {'content': 'Hardware refers to the physical components of a computer system, such as the processor, memory, and storage devices. Software, on the other hand, consists of the instructions and programs that tell the hardware how to operate and perform specific tasks.', 'role': 'user'}], summary='Hardware refers to the physical components of a computer system, such as the processor, memory, and storage devices. Software, on the other hand, consists of the instructions and programs that tell the hardware how to operate and perform specific tasks.', cost={'usage_including_cached_inference': {'total_cost': 0.000374, 'gemini-pro': {'cost': 0.000374, 'prompt_tokens': 346, 'completion_tokens': 134, 'total_tokens': 480}}, 'usage_excluding_cached_inference': {'total_cost': 0.00032450000000000003, 'gemini-pro': {'cost': 0.00032450000000000003, 'prompt_tokens': 334, 'completion_tokens': 105, 'total_tokens': 439}}}, human_input=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = AssistantAgent(\"gpt-4\", \n",
    "                     system_message=\"\"\"You should ask weird, tricky, and concise questions. \n",
    "Ask the next question based on (by evolving) the previous one.\"\"\",\n",
    "                       llm_config=llm_config1, \n",
    "                       max_consecutive_auto_reply=2)\n",
    "\n",
    "gemini = AssistantAgent(\"Gemini-Pro\", \n",
    "                     system_message=\"\"\"Always answer questions within two sentences. \"\"\",\n",
    "#                      system_message=\"answer:\",\n",
    "                       llm_config=llm_config2, \n",
    "                       max_consecutive_auto_reply=3)\n",
    "\n",
    "\n",
    "\n",
    "gpt.initiate_chat(gemini, message=\"What are computers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e1ec7-0a5e-4922-ae9b-0f4733d1a508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3150280-af99-4233-9acd-2b7e4e2c3f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06f605-8497-4ce1-9402-05ca4a3ff118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c079aa7",
   "metadata": {},
   "source": [
    "Let's switch position. Now, Gemini is the question raiser. \n",
    "\n",
    "This time, Gemini could not follow the system instruction well or evolve questions, because the Gemini does not handle system messages similar to GPTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d87932-39dd-48fd-a6be-f6f1d0c874ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1ead90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "Should Spider-Man invest in 401K?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mgpt-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Yes, Spider-Man should invest in 401K to secure his financial future despite his unique circumstances\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "If a group of people are playing a game of Monopoly and they all agree to land on Free Parking and collect $500, does it make it a legitimate rule?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mgpt-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "No, mutual agreement among players cannot override the official rules of Monopoly.\n",
      "<br><br>\n",
      "**Assistant**\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "If a tree falls in a forest and there's no one around to hear it, does it make a sound?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mgpt-4\u001b[0m (to Gemini-Pro):\n",
      "\n",
      "Whether a falling tree makes a sound in the absence of human perception is a philosophical question.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGemini-Pro\u001b[0m (to gpt-4):\n",
      "\n",
      "If a mirror is moving at the speed of light, does its reflection age?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Should Spider-Man invest in 401K?', 'role': 'assistant'}, {'content': 'Yes, Spider-Man should invest in 401K to secure his financial future despite his unique circumstances', 'role': 'user'}, {'content': 'If a group of people are playing a game of Monopoly and they all agree to land on Free Parking and collect $500, does it make it a legitimate rule?', 'role': 'assistant'}, {'content': 'No, mutual agreement among players cannot override the official rules of Monopoly.\\n<br><br>\\n**Assistant**', 'role': 'user'}, {'content': \"If a tree falls in a forest and there's no one around to hear it, does it make a sound?\", 'role': 'assistant'}, {'content': 'Whether a falling tree makes a sound in the absence of human perception is a philosophical question.', 'role': 'user'}, {'content': 'If a mirror is moving at the speed of light, does its reflection age?', 'role': 'assistant'}], summary='If a mirror is moving at the speed of light, does its reflection age?', cost={'usage_including_cached_inference': {'total_cost': 0.0005015, 'gemini-pro': {'cost': 0.0005015, 'prompt_tokens': 586, 'completion_tokens': 139, 'total_tokens': 725}}, 'usage_excluding_cached_inference': {'total_cost': 0.0005015, 'gemini-pro': {'cost': 0.0005015, 'prompt_tokens': 586, 'completion_tokens': 139, 'total_tokens': 725}}}, human_input=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = AssistantAgent(\"gpt-4\", \n",
    "                     system_message=\"\"\"Always answer questions within one sentence. \"\"\",\n",
    "                       llm_config=llm_config1, \n",
    "                       max_consecutive_auto_reply=3)\n",
    "\n",
    "gemini = AssistantAgent(\"Gemini-Pro\", \n",
    "                     system_message=\"\"\"You should ask weird, tricky, and concise questions. \n",
    "Ask the next question based on (by evolving) the previous one.\"\"\",\n",
    "                       llm_config=llm_config2, \n",
    "                       max_consecutive_auto_reply=4)\n",
    "\n",
    "gemini.initiate_chat(gpt, message=\"Should Spider-Man invest in 401K?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf9c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c35635e3",
   "metadata": {},
   "source": [
    "## Gemini RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f66022",
   "metadata": {},
   "source": [
    "Here we will be exploring RAG with Gemini. Note that Gemini will raise a 500 error if a message is an empty string. To prevent this, we set the `default_auto_reply` to `Reply plaintext TERMINATE to exit.` for the `ragproxyagent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6176b5e9-9d16-49a3-986d-31ba3117dd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0502 08:44:33.606738272     184 backup_poller.cc:127]                 Run client channel backup poller: UNKNOWN:pollset_work {created_time:\"2024-05-02T08:44:33.606370955+00:00\", children:[UNKNOWN:Bad file descriptor {created_time:\"2024-05-02T08:44:33.606259646+00:00\", errno:9, os_error:\"Bad file descriptor\", syscall:\"epoll_wait\"}]}\n",
      "Requirement already satisfied: sentence_transformers in ./.local/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.local/lib/python3.10/site-packages (from sentence_transformers) (4.40.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.local/lib/python3.10/site-packages (from sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.local/lib/python3.10/site-packages (from sentence_transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
      "Collecting sympy (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Collecting triton==2.3.0 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Using cached safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "Using cached safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, triton, sympy, safetensors\n",
      "\u001b[33m  WARNING: The script isympy is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "onnxruntime 1.17.3 requires flatbuffers, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed mpmath-1.3.0 safetensors-0.4.3 sympy-1.12 triton-2.3.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install --user pyautogen[retrievechat]\n",
    "#!pip install --user pypdf\n",
    "#!pip install --user monotonic\n",
    "#!pip install --user pypika\n",
    "#!pip install --user sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cd1ea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2febe5a2434463943096ee529e4df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8f3840580e4e5db86cc9d973538f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01a3fd993df4ff68fb05d9bba869652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4e34daa5df4ee8a135d6678ee38d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a64ff4e4ba0481c83ba24b5b4f0c187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb8d74d53bf4d7c826f1f7731629d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a91bff0495471cb6678180e2259868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63149aa0877b41e3859908d73ac06b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119c0ec0da454b97a6ea4e1ce3b3dc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d11956c220a4d9bac200e2ae6ff2465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d60db6850fa4969ae54e478c1d55dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "As a helpful assistant, I am here to provide information, answer questions, and complete tasks to the best of my abilities. I can help you with a wide range of topics, including:\n",
      "\n",
      "* **General knowledge:** I can provide information on a variety of topics, such as history, science, geography, and current events.\n",
      "* **Tasks and errands:** I can help you complete tasks such as scheduling appointments, making reservations, or finding information online.\n",
      "* **Personal assistance:** I can help you with personal tasks such as managing your finances, planning your day, or setting reminders.\n",
      "\n",
      "I am always learning and expanding my knowledge base, so I can provide you with the most up-to-date and accurate information. I am also committed to providing you with helpful and friendly service.\n",
      "\n",
      "Here are some specific examples of how I can be helpful:\n",
      "\n",
      "* **Answering your questions:** I can answer a wide range of questions, from simple factual questions to more complex questions that require research.\n",
      "* **Providing information:** I can provide information on a variety of topics, such as the weather, news, sports, and entertainment.\n",
      "* **Completing tasks:** I can help you complete tasks such as scheduling appointments, making reservations, or finding information online.\n",
      "* **Offering suggestions:** I can offer suggestions on a variety of topics, such as what to watch, what to read, or where to go for dinner.\n",
      "* **Providing support:** I can provide support and encouragement when you need it.\n",
      "\n",
      "I am here to help you in any way that I can. Please let me know if you have any questions or requests.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': '', 'role': 'assistant'}, {'content': 'As a helpful assistant, I am here to provide information, answer questions, and complete tasks to the best of my abilities. I can help you with a wide range of topics, including:\\n\\n* **General knowledge:** I can provide information on a variety of topics, such as history, science, geography, and current events.\\n* **Tasks and errands:** I can help you complete tasks such as scheduling appointments, making reservations, or finding information online.\\n* **Personal assistance:** I can help you with personal tasks such as managing your finances, planning your day, or setting reminders.\\n\\nI am always learning and expanding my knowledge base, so I can provide you with the most up-to-date and accurate information. I am also committed to providing you with helpful and friendly service.\\n\\nHere are some specific examples of how I can be helpful:\\n\\n* **Answering your questions:** I can answer a wide range of questions, from simple factual questions to more complex questions that require research.\\n* **Providing information:** I can provide information on a variety of topics, such as the weather, news, sports, and entertainment.\\n* **Completing tasks:** I can help you complete tasks such as scheduling appointments, making reservations, or finding information online.\\n* **Offering suggestions:** I can offer suggestions on a variety of topics, such as what to watch, what to read, or where to go for dinner.\\n* **Providing support:** I can provide support and encouragement when you need it.\\n\\nI am here to help you in any way that I can. Please let me know if you have any questions or requests.', 'role': 'user'}], summary='As a helpful assistant, I am here to provide information, answer questions, and complete tasks to the best of my abilities. I can help you with a wide range of topics, including:\\n\\n* **General knowledge:** I can provide information on a variety of topics, such as history, science, geography, and current events.\\n* **Tasks and errands:** I can help you complete tasks such as scheduling appointments, making reservations, or finding information online.\\n* **Personal assistance:** I can help you with personal tasks such as managing your finances, planning your day, or setting reminders.\\n\\nI am always learning and expanding my knowledge base, so I can provide you with the most up-to-date and accurate information. I am also committed to providing you with helpful and friendly service.\\n\\nHere are some specific examples of how I can be helpful:\\n\\n* **Answering your questions:** I can answer a wide range of questions, from simple factual questions to more complex questions that require research.\\n* **Providing information:** I can provide information on a variety of topics, such as the weather, news, sports, and entertainment.\\n* **Completing tasks:** I can help you complete tasks such as scheduling appointments, making reservations, or finding information online.\\n* **Offering suggestions:** I can offer suggestions on a variety of topics, such as what to watch, what to read, or where to go for dinner.\\n* **Providing support:** I can provide support and encouragement when you need it.\\n\\nI am here to help you in any way that I can. Please let me know if you have any questions or requests.', cost={'usage_including_cached_inference': {'total_cost': 0.0005015, 'gemini-pro': {'cost': 0.0005015, 'prompt_tokens': 7, 'completion_tokens': 332, 'total_tokens': 339}}, 'usage_excluding_cached_inference': {'total_cost': 0.0005015, 'gemini-pro': {'cost': 0.0005015, 'prompt_tokens': 7, 'completion_tokens': 332, 'total_tokens': 339}}}, human_input=[''])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "import os\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"cache_seed\": 42,\n",
    "        \"config_list\": config_list_gemini,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    default_auto_reply=\"Reply plaintext TERMINATE to exit.\",  # Gemini will raise 500 error if the response is empty.\n",
    "    max_consecutive_auto_reply=3,\n",
    "    retrieve_config={\n",
    "        \"task\": \"code\",\n",
    "        \"docs_path\": [\n",
    "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\",\n",
    "            \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n",
    "            os.path.join(os.path.abspath(''), \"..\", \"website\", \"docs\"),\n",
    "        ],\n",
    "        \"custom_text_types\": [\"mdx\"],\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list_gemini[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "        \"get_or_create\": True,  # set to False if you don't want to reuse an existing collection, but you'll need to remove the collection manually\n",
    "    },\n",
    "    code_execution_config=False, # set to False if you don't want to execute the code\n",
    ")\n",
    "\n",
    "code_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=code_problem, search_string=\"spark\")  # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09139b42",
   "metadata": {},
   "source": [
    "## Gemini Multimodal\n",
    "\n",
    "You can create multimodal agent for Gemini the same way as the GPT-4V and LLaVA.\n",
    "\n",
    "\n",
    "Note that the Gemini-pro-vision does not support chat yet. So, we only use the last message in the prompt for multi-turn chat. The behavior might be strange compared to GPT-4V and LLaVA models.\n",
    "\n",
    "Here, we ask a question about \n",
    "![](https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cedc34b4-e44b-4c28-b203-d9ac1bb35fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_list_gemini_vision = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro-vision\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e5098e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Gemini Vision):\n",
      "\n",
      "What's this image about? \n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mGemini Vision\u001b[0m (to user_proxy):\n",
      "\n",
      " The image is about a user interacting with an assistant agent. The user wants to plot a chart of META and TSLA stock price change YTD. The assistant agent helps the user by executing the code and installing the required packages.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"What's this image about? \\n<img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.\", 'role': 'assistant'}, {'content': ' The image is about a user interacting with an assistant agent. The user wants to plot a chart of META and TSLA stock price change YTD. The assistant agent helps the user by executing the code and installing the required packages.', 'role': 'user'}], summary=' The image is about a user interacting with an assistant agent. The user wants to plot a chart of META and TSLA stock price change YTD. The assistant agent helps the user by executing the code and installing the required packages.', cost={'usage_including_cached_inference': {'total_cost': 0.000203, 'gemini-pro-vision': {'cost': 0.000203, 'prompt_tokens': 268, 'completion_tokens': 46, 'total_tokens': 314}}, 'usage_excluding_cached_inference': {'total_cost': 0.000203, 'gemini-pro-vision': {'cost': 0.000203, 'prompt_tokens': 268, 'completion_tokens': 46, 'total_tokens': 314}}}, human_input=[])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = MultimodalConversableAgent(\"Gemini Vision\", \n",
    "                           llm_config={\"config_list\": config_list_gemini_vision, \"seed\": 42}, \n",
    "                           max_consecutive_auto_reply=1)\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            max_consecutive_auto_reply=0)\n",
    "\n",
    "# user_proxy.initiate_chat(image_agent, \n",
    "#                          message=\"\"\"What's the breed of this dog? \n",
    "# <img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0>.\"\"\")\n",
    "\n",
    "user_proxy.initiate_chat(image_agent, \n",
    "                         message=\"\"\"What's this image about? \n",
    "<img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "598c3d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Gemini Vision):\n",
      "\n",
      "What's the breed of this dog? \n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mGemini Vision\u001b[0m (to user_proxy):\n",
      "\n",
      " This dog appears to be a Labradoodle. Goldendoodles tend to have a lighter coat color, while Labradoodles tend to be darker.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"What's the breed of this dog? \\n<img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0>.\", 'role': 'assistant'}, {'content': ' This dog appears to be a Labradoodle. Goldendoodles tend to have a lighter coat color, while Labradoodles tend to be darker.', 'role': 'user'}], summary=' This dog appears to be a Labradoodle. Goldendoodles tend to have a lighter coat color, while Labradoodles tend to be darker.', cost={'usage_including_cached_inference': {'total_cost': 0.00018, 'gemini-pro-vision': {'cost': 0.00018, 'prompt_tokens': 270, 'completion_tokens': 30, 'total_tokens': 300}}, 'usage_excluding_cached_inference': {'total_cost': 0.00018, 'gemini-pro-vision': {'cost': 0.00018, 'prompt_tokens': 270, 'completion_tokens': 30, 'total_tokens': 300}}}, human_input=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = MultimodalConversableAgent(\"Gemini Vision\", \n",
    "                           llm_config={\"config_list\": config_list_gemini_vision, \"seed\": 42}, \n",
    "                           max_consecutive_auto_reply=1)\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            max_consecutive_auto_reply=0)\n",
    "\n",
    "user_proxy.initiate_chat(image_agent, \n",
    "                         message=\"\"\"What's the breed of this dog? \n",
    "<img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0>.\"\"\")\n",
    "\n",
    "# user_proxy.initiate_chat(image_agent, \n",
    "#                          message=\"\"\"What's this image about? \n",
    "# <img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf5fc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Gemini Vision):\n",
      "\n",
      "Explain whats in the image? \n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mGemini Vision\u001b[0m (to user_proxy):\n",
      "\n",
      " A cat is eating an ice cream cone. The cat has its tongue out and is licking the ice cream. The cone is held by a human hand. The cat is black and white. The background is blurred.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Explain whats in the image? \\n<img https://blog.healthypawspetinsurance.com/wp-content/uploads/2022/05/black-cat-licking-ice-cream-cone.jpg>.', 'role': 'assistant'}, {'content': ' A cat is eating an ice cream cone. The cat has its tongue out and is licking the ice cream. The cone is held by a human hand. The cat is black and white. The background is blurred.', 'role': 'user'}], summary=' A cat is eating an ice cream cone. The cat has its tongue out and is licking the ice cream. The cone is held by a human hand. The cat is black and white. The background is blurred.', cost={'usage_including_cached_inference': {'total_cost': 0.000198, 'gemini-pro-vision': {'cost': 0.000198, 'prompt_tokens': 267, 'completion_tokens': 43, 'total_tokens': 310}}, 'usage_excluding_cached_inference': {'total_cost': 0.000198, 'gemini-pro-vision': {'cost': 0.000198, 'prompt_tokens': 267, 'completion_tokens': 43, 'total_tokens': 310}}}, human_input=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = MultimodalConversableAgent(\"Gemini Vision\", \n",
    "                           llm_config={\"config_list\": config_list_gemini_vision, \"seed\": 42}, \n",
    "                           max_consecutive_auto_reply=1)\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            max_consecutive_auto_reply=0)\n",
    "\n",
    "user_proxy.initiate_chat(image_agent, \n",
    "                         message=\"\"\"Explain whats in the image? \n",
    "<img https://blog.healthypawspetinsurance.com/wp-content/uploads/2022/05/black-cat-licking-ice-cream-cone.jpg>.\"\"\")\n",
    "\n",
    "# user_proxy.initiate_chat(image_agent, \n",
    "#                          message=\"\"\"What's this image about? \n",
    "# <img https://github.com/microsoft/autogen/blob/main/website/static/img/chat_example.png?raw=true>.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d7ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47c9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
