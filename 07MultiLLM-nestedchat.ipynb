{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5f8911-17dd-4291-8d62-1c374fc4604c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pdb\n",
    "import os\n",
    "import re\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, Agent, UserProxyAgent, ConversableAgent\n",
    "\n",
    "from autogen.agentchat.contrib.img_utils import get_image_data, _to_pil\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "from termcolor import colored\n",
    "import random\n",
    "\n",
    "from autogen.code_utils import DEFAULT_MODEL, UNKNOWN, content_str, execute_code, extract_code, infer_lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8cff907-5097-40f0-8046-89f6e34ada80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_list_gemini = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST_456\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gemini-pro\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91d5967-0bb3-482a-a10b-4bb4806ec846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The Number Agent always returns the same numbers.\n",
    "number_agent = ConversableAgent(\n",
    "    name=\"Number_Agent\",\n",
    "    system_message=\"You return me the numbers I give you, one number each line.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Adder Agent adds 1 to each number it receives.\n",
    "adder_agent = ConversableAgent(\n",
    "    name=\"Adder_Agent\",\n",
    "    system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Multiplier Agent multiplies each number it receives by 2.\n",
    "multiplier_agent = ConversableAgent(\n",
    "    name=\"Multiplier_Agent\",\n",
    "    system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Subtracter Agent subtracts 1 from each number it receives.\n",
    "subtracter_agent = ConversableAgent(\n",
    "    name=\"Subtracter_Agent\",\n",
    "    system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Divider Agent divides each number it receives by 2.\n",
    "divider_agent = ConversableAgent(\n",
    "    name=\"Divider_Agent\",\n",
    "    system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3ce60f-b692-4bd7-95e0-938bd4f3144a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The `description` attribute is a string that describes the agent.\n",
    "# It can also be set in `ConversableAgent` constructor.\n",
    "adder_agent.description = \"Add 1 to each input number.\"\n",
    "multiplier_agent.description = \"Multiply each input number by 2.\"\n",
    "subtracter_agent.description = \"Subtract 1 from each input number.\"\n",
    "divider_agent.description = \"Divide each input number by 2.\"\n",
    "number_agent.description = \"Return the numbers given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958eb06f-33d7-43cc-ad67-686fa7322ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.gettempdir()\n",
    "\n",
    "arithmetic_agent = ConversableAgent(\n",
    "    name=\"Arithmetic_Agent\",\n",
    "    llm_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    # This agent will always require human input to make sure the code is\n",
    "    # safe to execute.\n",
    "    code_execution_config={\"use_docker\": False, \"work_dir\": temp_dir},\n",
    ")\n",
    "\n",
    "code_writer_agent = ConversableAgent(\n",
    "    name=\"Code_Writer_Agent\",\n",
    "    system_message=\"You are a code writer. You write Python script in Markdown code blocks.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "poetry_agent = ConversableAgent(\n",
    "    name=\"Poetry_Agent\",\n",
    "    system_message=\"You are an AI poet.\",\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa3b729-b1b9-4397-9d94-d2ea0a02cab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogen import GroupChat\n",
    "\n",
    "group_chat = GroupChat(\n",
    "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n",
    "    messages=[],\n",
    "    max_round=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8018d42b-c930-4ce0-9b7c-e659cf354abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogen import GroupChatManager\n",
    "\n",
    "group_chat_manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803ba662-4470-4411-be46-ec32430a7af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_chat_with_introductions = GroupChat(\n",
    "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n",
    "    messages=[],\n",
    "    max_round=6,\n",
    "    send_introductions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb08bb0d-9f12-4345-9ffa-1df504d142ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "My number is 3, I want to turn it into 13.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "4\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "6\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "12.8\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/autogen/agentchat/chat.py:47: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "24.8\n",
      "12.4\n",
      "6.2\n",
      "3.1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "1.55\n",
      "0.775\n",
      "0.3875\n",
      "0.19375\n",
      "0.096875\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mNumber_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Turn this number to 32.\n",
      "Context: \n",
      "1.55\n",
      "0.775\n",
      "0.3875\n",
      "0.19375\n",
      "0.096875\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "3.1\n",
      "1.55\n",
      "0.775\n",
      "0.3875\n",
      "0.19375\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "0.096875\n",
      "0.0484375\n",
      "0.02421875\n",
      "0.012109375\n",
      "0.0060546875\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "0.00302734375\n",
      "0.001513671875\n",
      "0.0007568359375\n",
      "0.00037841796875\n",
      "0.000189208984375\n",
      "0.0000946044921875\n",
      "0.00004730224609375\n",
      "0.000023651123046875\n",
      "0.0000118255615234375\n",
      "0.00000591278076171875\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "2.55\n",
      "1.775\n",
      "0.3875\n",
      "0.19375\n",
      "0.096875\n",
      "4.1\n",
      "2.55\n",
      "1.775\n",
      "0.3875\n",
      "0.19375\n",
      "0.096875\n",
      "0.0484375\n",
      "0.02421875\n",
      "0.012109375\n",
      "0.0060546875\n",
      "0.00302734375\n",
      "0.001513671875\n",
      "0.0007568359375\n",
      "0.00037841796875\n",
      "0.000189208984375\n",
      "0.0000946044921875\n",
      "0.00004730224609375\n",
      "0.000023651123046875\n",
      "0.0000118255615234375\n",
      "0.00000591278076171875\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdder_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "0.000002956390380859375\n",
      "0.0000014781951904296875\n",
      "0.00000073909759521484375\n",
      "0.000000369548797607421875\n",
      "0.0000001847743988037109375\n",
      "0.00000009238719940185546875\n",
      "0.000000046193599700927734375\n",
      "0.0000000230967998504638671875\n",
      "0.00000001154839992523193359375\n",
      "0.000000005774199962615966796875\n",
      "0.0000000028870999813079833984375\n",
      "0.00000000144354999065399169921875\n",
      "0.000000000721774995326995849609375\n",
      "0.0000000003608874976634979248046875\n",
      "0.00000000018044374883174896240234375\n",
      "0.000000000090221874415874481201171875\n",
      "0.0000000000451109372079372406005859375\n",
      "0.00000000002255546860396862030029296875\n",
      "0.000000000011277734301984310150146484375\n",
      "0.0000000000056388671509921550750732421875\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's use the group chat with introduction messages created above.\n",
    "group_chat_manager_with_intros = GroupChatManager(\n",
    "    groupchat=group_chat_with_introductions,\n",
    "    llm_config={\"config_list\": config_list_gemini, \"seed\":42},\n",
    ")\n",
    "\n",
    "# Start a sequence of two-agent chats between the number agent and\n",
    "# the group chat manager.\n",
    "chat_result = number_agent.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": group_chat_manager_with_intros,\n",
    "            \"message\": \"My number is 3, I want to turn it into 13.\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": group_chat_manager_with_intros,\n",
    "            \"message\": \"Turn this number to 32.\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "134fefa0-88f1-4603-ab72-5a1ac50b0f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nested_chats = [\n",
    "    {\n",
    "        \"recipient\": group_chat_manager_with_intros,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_prompt\": \"Summarize the sequence of operations used to turn \" \"the source number into target number.\",\n",
    "    },\n",
    "    {\n",
    "        \"recipient\": code_writer_agent,\n",
    "        \"message\": \"Write a Python script to verify the arithmetic operations is correct.\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "    {\n",
    "        \"recipient\": poetry_agent,\n",
    "        \"message\": \"Write a poem about it.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"last_msg\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d7f64d-c204-46fe-9b9e-7a537460f98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arithmetic_agent.register_nested_chats(\n",
    "    nested_chats,\n",
    "    # The trigger function is used to determine if the agent should start the nested chat\n",
    "    # given the sender agent.\n",
    "    # In this case, the arithmetic agent will not start the nested chats if the sender is\n",
    "    # from the nested chats' recipient to avoid recursive calls.\n",
    "    trigger=lambda sender: sender not in [group_chat_manager_with_intros, code_writer_agent, poetry_agent],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b324d609-da1d-4eda-8b7c-2583a791d82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to the sender. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  4\n"
     ]
    }
   ],
   "source": [
    "# Instead of using `initiate_chat` method to start another conversation,\n",
    "# we can use the `generate_reply` method to get single reply to a message directly.\n",
    "reply = arithmetic_agent.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I have a number 3 and I want to turn it into 7.\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc55179a-c5bf-4315-b1dc-f49c640ee256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide feedback to the sender. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mArithmetic_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "I have a number 3 and I want to turn it into 7.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "6\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "12\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "1428\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "16243248\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "3264\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instead of using `initiate_chat` method to start another conversation,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# we can use the `generate_reply` method to get single reply to a message directly.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[43marithmetic_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI have a number 3 and I want to turn it into 7.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:1934\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 1934\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m   1936\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:389\u001b[0m, in \u001b[0;36mConversableAgent._summary_from_nested_chats\u001b[0;34m(chat_queue, recipient, messages, sender, config)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_to_run:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43minitiate_chats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_to_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, res[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msummary\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/autogen/agentchat/chat.py:198\u001b[0m, in \u001b[0;36minitiate_chats\u001b[0;34m(chat_queue)\u001b[0m\n\u001b[1;32m    193\u001b[0m     _chat_carryover \u001b[38;5;241m=\u001b[39m [_chat_carryover]\n\u001b[1;32m    194\u001b[0m chat_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarryover\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _chat_carryover \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m    195\u001b[0m     r\u001b[38;5;241m.\u001b[39msummary \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(finished_chats) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m finished_chat_indexes_to_exclude_from_carryover\n\u001b[1;32m    196\u001b[0m ]\n\u001b[0;32m--> 198\u001b[0m \u001b[43m__post_carryover_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m sender \u001b[38;5;241m=\u001b[39m chat_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msender\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    200\u001b[0m chat_res \u001b[38;5;241m=\u001b[39m sender\u001b[38;5;241m.\u001b[39minitiate_chat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_info)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/autogen/agentchat/chat.py:119\u001b[0m, in \u001b[0;36m__post_carryover_processing\u001b[0;34m(chat_info)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chat_info:\n\u001b[1;32m    114\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage is not provided in a chat_queue entry. input() will be called to get the initial message.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    118\u001b[0m print_carryover \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 119\u001b[0m     \u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchat_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcarryover\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarryover\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m chat_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarryover\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m message \u001b[38;5;241m=\u001b[39m chat_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "# Instead of using `initiate_chat` method to start another conversation,\n",
    "# we can use the `generate_reply` method to get single reply to a message directly.\n",
    "reply = arithmetic_agent.generate_reply(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I have a number 3 and I want to turn it into 7.\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6dbaa-7eac-42cc-87f8-3347ae2c2861",
   "metadata": {},
   "source": [
    "A poem is returned as the response, which describes the transformation attempt from 3 to 7.\n",
    "\n",
    "The implementation of the nested chats handler makes use of the register_reply method, which allows you to make extensive customization to ConversableAgent. The GroupChatManager uses the same mechanism to implement the group chat.\n",
    "\n",
    "Nested chat is a powerful conversation pattern that allows you to package complex workflows into a single agent. You can hide tool usages within a single agent by having the tool-caller agent starts a nested chat with a tool-executor agent and then use the result of the nested chat to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238be659-7052-4c65-980a-e6acef02b8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
